{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQmWTRMz11z0Od6+0RLylK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/RAG-LangChain/blob/main/LC_015_RAG_EVAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† RAG Pipeline Evaluation\n",
        "\n",
        "### üéØ Objective\n",
        "\n",
        "This notebook sets out to evaluate the performance of a **Retrieval-Augmented Generation (RAG)** pipeline designed to answer questions using a curated set of business and economic documents. Our goal was to ensure that the system not only retrieves relevant content but also generates factually accurate and helpful answers grounded in that content.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Key Challenges\n",
        "\n",
        "1. **Knowledge Cutoff in LLM Evaluation**\n",
        "   Our evaluator LLM (GPT-4o-mini) has a knowledge cutoff in 2023, while our documents include facts and data from 2024‚Äì2025. This caused the evaluator to incorrectly reject some answers as ‚Äúfactually incorrect‚Äù despite being accurate and retrieved from trusted sources.\n",
        "\n",
        "2. **Ensuring Context-Aware Judging**\n",
        "   We needed to ensure the evaluator judged answers based **only on the retrieved document chunks**, not on the LLM‚Äôs prior training knowledge or assumptions.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Solutions Implemented\n",
        "\n",
        "* Built a clean RAG chain that retrieves top-`k` chunks and generates answers using GPT-4.\n",
        "* Captured both the **generated answer** and the **retrieved context** for each question.\n",
        "* Designed an evaluation function that passed the **same context** to an LLM-based evaluator.\n",
        "* Updated the evaluator prompt to trust document context and ignore its own outdated knowledge.\n",
        "\n",
        "---\n",
        "\n",
        "### üìà Results\n",
        "\n",
        "* **All test questions produced factually grounded, well-written answers.**\n",
        "* Evaluator marked all answers **\"acceptable\"** once the context-aware judgment fix was applied.\n",
        "* The RAG system successfully explained economic indicators and their impacts on local businesses in a clear, actionable manner.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Conclusion\n",
        "\n",
        "This notebook demonstrates a full, working example of how to evaluate a modern RAG system with:\n",
        "\n",
        "* Document-grounded generation\n",
        "* Faithfulness-aware evaluation\n",
        "* Scalable automation using OpenAI models\n",
        "\n",
        "The pipeline is now well-suited for expansion, logging, QA review, or integration into production systems.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-N0b7TNaM-eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pip Install Packages"
      ],
      "metadata": {
        "id": "KvNkrKlLz8JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet \\\n",
        "    langchain \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-openai \\\n",
        "    langchain-community \\\n",
        "    chromadb \\\n",
        "    python-dotenv \\\n",
        "    transformers \\\n",
        "    accelerate \\\n",
        "    sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Iz8hiw3pqrZ",
        "outputId": "8fe50b72-f018-433c-a18e-2772a70b70ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Libaries"
      ],
      "metadata": {
        "id": "uBzB4d5mr_BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üåø Environment setup\n",
        "import os                                 # File paths and OS interaction\n",
        "from dotenv import load_dotenv            # Load environment variables from .env file\n",
        "import langchain; print(langchain.__version__)  # Check LangChain version\n",
        "import itertools\n",
        "\n",
        "# üìÑ Document loading and preprocessing\n",
        "from langchain_core.documents import Document                   # Base document type\n",
        "from langchain_community.document_loaders import TextLoader     # Loads plain text files\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Splits long docs into smaller chunks\n",
        "\n",
        "# üî¢ Embeddings + vector storage\n",
        "from langchain_huggingface import HuggingFaceEmbeddings         # HuggingFace embedding model\n",
        "from langchain.vectorstores import Chroma                       # Persistent vector DB (Chroma)\n",
        "\n",
        "# üí¨ Prompting + output\n",
        "from langchain_openai.chat_models.base import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate           # Chat-style prompt templates\n",
        "from langchain_core.output_parsers import StrOutputParser       # Converts model output to string\n",
        "\n",
        "# üîó Chains / pipelines\n",
        "from langchain_core.runnables import Runnable, RunnableLambda   # Compose custom pipelines\n",
        "\n",
        "# üß† (Optional) Hugging Face LLM client setup\n",
        "# from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace  # For HF inference API\n",
        "\n",
        "# üßæ Pretty printing\n",
        "import textwrap                         # Format long strings for printing\n",
        "from pprint import pprint               # Nicely format nested data structures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q58WFbWobSR",
        "outputId": "843a9bbf-770f-4f13-dc0e-a157be05fcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET MODEL PARAMS"
      ],
      "metadata": {
        "id": "r0YiVfaGBqfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load API key\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load token from .env.\n",
        "load_dotenv(\"/content/API_KEYS.env\", override=True)\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# SET MODEL PARAMS\n",
        "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
        "CHUNK_SIZE = 200\n",
        "CHUNK_OVERLAP = 50\n",
        "K = 2\n",
        "\n",
        "LLM_MODEL = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0.4  # Moderate creativity; adjust as needed\n",
        ")"
      ],
      "metadata": {
        "id": "LEK5hdgCBp_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üßæ Document Cleaning\n",
        "\n",
        "### üßæ 1. **Load the `.txt` files**\n",
        "\n",
        "We‚Äôll loop through all files in the folder using `TextLoader`.\n",
        "\n",
        "### üßπ 2. **Cleaning**\n",
        "\n",
        "Basic cleaning (e.g. stripping newlines, extra whitespace) is often helpful **before splitting**, especially if the files came from exports or copy-paste.\n",
        "\n",
        "### ‚úÇÔ∏è 3. **Split into chunks**\n",
        "\n",
        "We‚Äôll use `RecursiveCharacterTextSplitter` to chunk documents (typically 500‚Äì1000 characters with slight overlap for context continuity).\n",
        "\n",
        "---\n",
        "\n",
        "### üßº Why Basic Cleaning Helps\n",
        "\n",
        "* Removes linebreaks and blank lines that confuse LLMs\n",
        "* Avoids splitting chunks in weird places\n",
        "* Standardizes format before embedding\n",
        "\n",
        "Later you can add more advanced cleaning (e.g., remove boilerplate, normalize headers), but this is a solid default.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KmSqcFpbs5Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to documents\n",
        "docs_path = \"/content/CFFC\"\n",
        "\n",
        "# Step 1: Load all .txt files in the folder\n",
        "raw_documents = []\n",
        "for filename in os.listdir(docs_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_path = os.path.join(docs_path, filename)\n",
        "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "        docs = loader.load()\n",
        "        raw_documents.extend(docs)\n",
        "\n",
        "print(f\"Loaded {len(raw_documents)} documents.\")\n",
        "\n",
        "# Step 2 (optional): Clean up newlines and extra whitespace\n",
        "def clean_doc(doc: Document) -> Document:\n",
        "    cleaned = \" \".join(doc.page_content.split())  # Removes newlines & extra spaces\n",
        "    return Document(page_content=cleaned, metadata=doc.metadata)\n",
        "\n",
        "cleaned_documents = [clean_doc(doc) for doc in raw_documents]\n",
        "\n",
        "# Step 3: Split documents into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP\n",
        ")\n",
        "\n",
        "chunked_documents = splitter.split_documents(cleaned_documents)\n",
        "\n",
        "print(f\"Split into {len(chunked_documents)} total chunks.\")\n",
        "\n",
        "# Preview the first 5 chunks\n",
        "print(f\"Showing first 5 of {len(chunked_documents)} chunks:\\n\")\n",
        "\n",
        "for i, doc in enumerate(chunked_documents[:5]):\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\\n\")\n",
        "    print(textwrap.fill(doc.page_content[:500], width=100))  # limit preview to 500 characters\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpbJPTIDrVm3",
        "outputId": "fc6e4038-e88e-45c3-d80d-b07118925bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5 documents.\n",
            "Split into 83 total chunks.\n",
            "Showing first 5 of 83 chunks:\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Source: /content/CFFC/CFFC_Features_UseCases.txt\n",
            "\n",
            "# üìä Forecasting You Can Trust in Uncertain Times We help mid-sized businesses stay ahead of sales\n",
            "volatility and protect their bottom line by cutting forecast errors in half ‚Äî using powerful machine\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Source: /content/CFFC/CFFC_Features_UseCases.txt\n",
            "\n",
            "forecast errors in half ‚Äî using powerful machine learning models. --- ## üöÄ Key Benefits at a Glance\n",
            "- Cut forecasting errors by **50% or more** - Detect changes in demand **before they impact cash\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Source: /content/CFFC/CFFC_Features_UseCases.txt\n",
            "\n",
            "changes in demand **before they impact cash flow** - Respond to opportunities with **confidence and\n",
            "speed** - Replace spreadsheets with **smarter, adaptive forecasting** --- ## ‚ö†Ô∏è 1. Risk: Can I\n",
            "\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Source: /content/CFFC/CFFC_Features_UseCases.txt\n",
            "\n",
            "adaptive forecasting** --- ## ‚ö†Ô∏è 1. Risk: Can I Avoid Costly Surprises? **Traditional Tools (Excel,\n",
            "QuickBooks):** - Assume tomorrow looks like yesterday - Miss sudden drops in demand or spikes in\n",
            "\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Source: /content/CFFC/CFFC_Features_UseCases.txt\n",
            "\n",
            "- Miss sudden drops in demand or spikes in costs - Under-forecast surges, causing missed growth\n",
            "**ML-Based Forecasting:** - Tracks volatility, promotions, and macro shifts - Alerts you early when\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Embed + Persist in Chroma\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hVMiFfU7ulqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up Hugging Face embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "\n",
        "# Step 2: Set up Chroma with persistence\n",
        "persist_dir = \"chroma_db\"\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunked_documents,\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=persist_dir\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Stored {len(chunked_documents)} chunks in Chroma at '{persist_dir}'\")"
      ],
      "metadata": {
        "id": "2EJR3GwqtXwu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "4f6a265f9dd741beb39b96a656deed29",
            "af51a599a29f4890b68a259a3ff3976e",
            "49919262366a4af592aca8320d2e52f6",
            "d9db345e2b0b4cfd9e7cceccfd356e60",
            "e8ea571669cc48b8ad684d451e3ff7ce",
            "2e677be4503b4ac7b7e5ee2ac002229e",
            "7259e379e8c54f7cbac56e03bbb7dd4d",
            "37532b27fb5a4ecca833c002fd2b31b1",
            "0bc0901936c848368c2d70ee5cccffe8",
            "d363e6d48c0748f9a8cf21857ef687b7",
            "825be34c386d46cb8e58f7b8df729251",
            "b0365825ec91484496a3ebfc11aa8dd2",
            "ea4722186345452497c38a989a2a6f3b",
            "470b52c1448a4e4b8a637de86df1a28f",
            "de4651d8e29a4e9385bf81b09a2e91de",
            "9f14216de78c4610b5a28755010fedb2",
            "93c1e6d4b57f48dd9301f4dc239a2adc",
            "9c38021f66ca4c3fb6b8eb12f207c951",
            "c4a35a5e72774da4901f08ef6210e45a",
            "55ca96b3489949f4b5d2ffb32980c8b8",
            "e21eacc1be474f9b9154ec3abddf1f10",
            "4a97bc7f58ee407196f25bb3a8d3f0a6",
            "56f9155247b045c1bb81095e37c5230b",
            "2269aa59d1ed4623ab5743b91b5447af",
            "b17f369c18d24596ae1ed729d54dbf9f",
            "5d36fa6866c64c92810587d193df3acb",
            "a61e592161754c64b551550831713c72",
            "e2268957d2fd40d0a802e8c5023fe618",
            "7c6aa9b230a54e789baf0fb99301b9ab",
            "341305f0061b4af89f481d1dd92c51a4",
            "b59d885a804144a6b4280f385fdd254e",
            "b93fd018e0d6465f82b6e852339450b8",
            "1b71e1c00c82491e9f45ddb35c81cfb0",
            "d4f25a30e31d4a1c9169c735e43491ff",
            "91754f1036ab4617a16db39dc4af1920",
            "870b85cdf864487b9cb4472322d3305d",
            "f76d7723f0364a41a62a12445d4a54ea",
            "9aec1be307b84ef69f651c7d2feb2899",
            "326b48c598594075b716931324381571",
            "756c9f7b4b3a400fbf7667fd63c6b9dd",
            "7e7e338bc01e49488d25c0e5282853f1",
            "135469cd41454113b80f2b66ec068507",
            "3b4ed4c65334495ea4f2528572321b10",
            "09399ceb67db49a895525e147179597e",
            "3038051ff6f84c6891b2afc32c1a7312",
            "304952e077624efeafa5783f9a2f995f",
            "f8aba255fe3d4bb3a77fcb46a0c20a2d",
            "53650d2597ed4a98aa0d5251dd187c8e",
            "2163d411ac654db3ae01746e9edc2c85",
            "127605b828df40bfa1c3cc07f91eea26",
            "900b4cd29eac4623906a10eb48397fc2",
            "4c919206feb94759b3940b5db301c4f7",
            "dd21fccf727b4a4590c7b4fbc738da42",
            "54876168c3324592bed4ed708ad2ef67",
            "fa7d49757f6e4d17baedbf231b16b21a",
            "cf021038d2484100b86197e65c7130c3",
            "42690eef2cc44ad9ac92a6ecdeda14b7",
            "f03670ab67854dbb8bf3341214e4ae86",
            "c3c46cec16094607a08285744bb99ba9",
            "66d5a9157f9246df99c3aa13cd1030fd",
            "1623ad337606435cb3e2ea8fcd0bc91f",
            "fb64b0a473074bf7a6b8b819cd103cae",
            "755080284ce84fd7922f71b8383eca3a",
            "5ef2cab44edc4c6b9d0e05f3b0fa4ebf",
            "f3856ceb316c4151bbda9b269bce7166",
            "9fa2c094f1414dff9a013ad57475f5bc",
            "4dc86064f1e14ec98c7c3253a70706af",
            "3ae44faebf1c4dc4b14896292afdf40c",
            "64eb64aba57b4da49768003faa2e4af5",
            "4f3a9a51b35a49328e42443c07d84743",
            "3c68f2a538694a2ba21f29e1e2f3ac74",
            "0f206021b979459395f45ede3dde1ef7",
            "c6a07536709846a288ab1ba572727596",
            "5a4d3bca63d343db88b118669ec39792",
            "b471e7980efc4d2b8deaa33b4ae2f645",
            "7157f3b3478149e19ae0af87238d9ea6",
            "445ff12ada884f6ba03cab9ad98d776c",
            "af2853d5d76a4998808c55f78b9d0275",
            "3443aec7d26b44b9a2256386d3af61d7",
            "909785f68fe4481690a193791db2594e",
            "6b00ac3609b44f9e820509c12ee3ef41",
            "9d2b5eeca01c4793a9094ed588418df1",
            "8f7a4d3d5c6048b882672248c753620f",
            "bbf7204bbd5b4c0c9ce47ee997a85a53",
            "76719392342e4ca3bc55aedc249dac23",
            "caa1bee2ad5c4d89bfa456393e9582e0",
            "eb59c9b75a4c4a2bab99b744dbc06b8c",
            "746fc6e89cf34165bd8325284b8687c6",
            "1ad0b50eb61b46eea304142b13b3e266",
            "864838aa73de4c99a6909e64b94679fb",
            "9a3cd7d23c514cdea2417226d04bb689",
            "e592c52fff7b45b19ceb669cd455e0ba",
            "7de2010da4de4698ba38f13bc1a3940c",
            "eebdab3fcd49487cb670ccbf0a68ee4e",
            "d62a3bb9db8a4c329815c565a05cd9fe",
            "3dc6dd643744435db2c4ca43a7197387",
            "6ce04739530d4155b6eb2da0acd54867",
            "fb4c55e331c3414fa51aa323553b04cb",
            "19f8624075fc465eaed4ce0e4285c69d",
            "1c84ab6bda584af6bcabebdbe8767f67",
            "dd372ba3130b439084ead7ff42aa0e49",
            "671000b689544089bef8ed2460211516",
            "9988cbbd90334aef83c6ec29747b2a46",
            "73d2b330f5924099bfadf967ee379189",
            "b5c27bef77ad484392ffebfbd5d6a569",
            "29e056c5f1114e8290c22390781f5a95",
            "17f55bd750764dcf8fc873b14edf04bf",
            "00ebc9c78582460abf706991f38f64bc",
            "9326ebf1ea7043fa8d6fec6dc3de1a88",
            "c5f18052c4624e38b8170e4af220e944",
            "780e688080f94d7d93cca6aa80f15008",
            "ca1feccad1504554a57fde6ded4a885c",
            "9a6ac5ac94184eb2ab15ca8458de8028",
            "35ec0f168c0d486ead8c832fc77ba68e",
            "2e3d2719241442e681a173c275f6b10a",
            "0ba5fc51e0b24e999a6053ba9948a514",
            "e6b226ccae2e44f0848d1429f14e9c81",
            "3f37443c27414d8e88f1f2216aec6c14",
            "d6cf61a275c141b581da327795e3911d",
            "fd7702496abf49de9f08218ab8e8becf",
            "6b019017d86d492298329e7f30545533"
          ]
        },
        "outputId": "57a258f2-2bf0-4bdb-b63a-c13edb2da214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f6a265f9dd741beb39b96a656deed29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0365825ec91484496a3ebfc11aa8dd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56f9155247b045c1bb81095e37c5230b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4f25a30e31d4a1c9169c735e43491ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3038051ff6f84c6891b2afc32c1a7312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf021038d2484100b86197e65c7130c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dc86064f1e14ec98c7c3253a70706af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af2853d5d76a4998808c55f78b9d0275"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ad0b50eb61b46eea304142b13b3e266"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c84ab6bda584af6bcabebdbe8767f67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "780e688080f94d7d93cca6aa80f15008"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Stored 83 chunks in Chroma at 'chroma_db'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Create the Retriever & Prompt Template"
      ],
      "metadata": {
        "id": "fWnzZXxuwv0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": K})\n",
        "\n",
        "# prompt template\n",
        "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful assistant that uses business documents to answer questions.\n",
        "Use the following context to answer the question as accurately as possible.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "rY_aJ08FwiX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 3: Create the RAG Chain & Run a Query!"
      ],
      "metadata": {
        "id": "89iAu-wbxB8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RAG chain\n",
        "rag_chain = (\n",
        "    RunnableLambda(lambda d: {\n",
        "        \"question\": d[\"question\"],\n",
        "        \"docs\": retriever.invoke(d[\"question\"])\n",
        "    })\n",
        "    | RunnableLambda(lambda d: {\n",
        "        \"context\": \"\\n\\n\".join([doc.page_content for doc in d[\"docs\"]]),\n",
        "        \"question\": d[\"question\"]\n",
        "    })\n",
        "    | prompt_template\n",
        "    | LLM_MODEL\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Invoke RAG\n",
        "response = rag_chain.invoke({\n",
        "    \"question\": \"What are the recent economic indicators in Gainesville that affect local businesses?\"\n",
        "})\n",
        "\n",
        "# Print response nicely\n",
        "import textwrap\n",
        "print(\"\\n\" + textwrap.fill(response, width=100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnbnq2JxKKZ",
        "outputId": "e3199a50-59f7-413a-9a5a-67ab8b4f911c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recent economic indicators in Gainesville that affect local businesses include declining consumer\n",
            "confidence, softening retail sales, and rising unemployment. These factors contribute to revenue\n",
            "uncertainty for even steady businesses, making it crucial for business owners to improve their\n",
            "forecasting to navigate these challenges effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EVALUATION"
      ],
      "metadata": {
        "id": "bZcIu2NNNH38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pydantic"
      ],
      "metadata": {
        "id": "vBY0gM_OsckR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a13325-99a8-464d-b78f-bbee6802dbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, ValidationError\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are an evaluator. Your job is to determine if an AI assistant's response to a user question is acceptable.\n",
        "\n",
        "You must check:\n",
        "- ‚úÖ Is it factually correct?\n",
        "- ‚úÖ Is it clear and well-written?\n",
        "- ‚úÖ Is it relevant to the user question?\n",
        "\n",
        "If the response is unclear, incorrect, or unhelpful, mark it unacceptable.\n",
        "\n",
        "Respond in **JSON only**:\n",
        "{\n",
        "  \"is_acceptable\": true or false,\n",
        "  \"feedback\": \"explanation of your reasoning\"\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zH_8kD0QschO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_response(user_question, agent_reply):\n",
        "    user_prompt = f\"\"\"\n",
        "User Question:\n",
        "{user_question}\n",
        "\n",
        "Agent Response:\n",
        "{agent_reply}\n",
        "\n",
        "Please evaluate the agent's response.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        temperature=0.0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        parsed = Evaluation.model_validate_json(response.choices[0].message.content)\n",
        "        return parsed\n",
        "    except ValidationError as e:\n",
        "        print(\"‚ùå Failed to parse response:\", e)\n",
        "        print(\"Raw response:\\n\", response.choices[0].message.content)\n",
        "        return Evaluation(is_acceptable=False, feedback=\"Parsing failed.\")"
      ],
      "metadata": {
        "id": "WYcQa58uscec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fquestion = \"What is the capital of France?\"\n",
        "correct_reply = \"The capital of France is Paris.\"\n",
        "bad_reply = \"France is in Europe, so it might be Berlin or Paris or Rome.\"\n",
        "\n",
        "def print_evaluation(label, result: Evaluation):\n",
        "    print(f\"\\n{label}\")\n",
        "    print(\"‚úÖ Acceptable:\" if result.is_acceptable else \"‚ùå Not acceptable.\")\n",
        "    print(\"üí¨ Feedback:\")\n",
        "    print(textwrap.fill(result.feedback, width=80))\n",
        "\n",
        "# Run and print both examples\n",
        "result1 = evaluate_response(question, correct_reply)\n",
        "print_evaluation(\"‚úÖ Good Reply Test:\", result1)\n",
        "\n",
        "result2 = evaluate_response(question, bad_reply)\n",
        "print_evaluation(\"‚ùå Bad Reply Test:\", result2)"
      ],
      "metadata": {
        "id": "5XCy9EF8Ytpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_test = [\n",
        "    \"What are the recent economic indicators in Gainesville that affect local businesses?\",\n",
        "    \"What is the recent trend in the Consumer Price Index (CPI) and how might it affect small businesses?\",\n",
        "    \"How has the Consumer Confidence Index changed since December 2024?\",\n",
        "    # \"What challenges might a business face if the Consumer Confidence Index drops?\"\n",
        "    # \"How can inflation affect staffing or wage budgets for small businesses?\",\n",
        "    # \"ow are CPI and retail sales different in their impact on business operations?\",\n",
        "    # \"Why should a local business owner monitor federal economic indicators like CPI, retail sales, and consumer confidence?\",\n",
        "    # \"What are three key actions a business owner can take in response to recent economic trends?\"\n",
        "]\n",
        "\n",
        "for i, q in enumerate(qa_test, 1):\n",
        "    answer = rag_chain.invoke({\"question\": q})\n",
        "    result = evaluate_response(q, answer)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(f\"üî¢ Question {i}\")\n",
        "    print(f\"üìå Question:\\n{textwrap.fill(q, width=100)}\\n\")\n",
        "    print(f\"üìù Answer:\\n{textwrap.fill(answer, width=100)}\\n\")\n",
        "    print(f\"‚úÖ Acceptable: {result.is_acceptable}\")\n",
        "    print(f\"üí¨ Feedback:\\n{textwrap.fill(result.feedback, width=100)}\")\n",
        "    print(\"=\"*100 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBM42Pt2YtnJ",
        "outputId": "2dea4175-633d-41c0-d81e-c14d22e9c87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "üî¢ Question 1\n",
            "üìå Question:\n",
            "What are the recent economic indicators in Gainesville that affect local businesses?\n",
            "\n",
            "üìù Answer:\n",
            "The recent economic indicators in Gainesville that affect local businesses include declining\n",
            "consumer confidence, softening retail sales, and rising unemployment. These factors contribute to\n",
            "revenue uncertainty for even steady businesses, making it challenging for them to forecast their\n",
            "financial performance accurately.\n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            "The response is factually correct, as it mentions relevant economic indicators that can affect local\n",
            "businesses. It is clear and well-written, providing a concise explanation of how these indicators\n",
            "impact financial performance. Additionally, it is relevant to the user's question about recent\n",
            "economic indicators in Gainesville.\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "üî¢ Question 2\n",
            "üìå Question:\n",
            "What is the recent trend in the Consumer Price Index (CPI) and how might it affect small businesses?\n",
            "\n",
            "üìù Answer:\n",
            "The recent trend in the Consumer Price Index (CPI) shows a rise from **315.56 to 319.77**, resulting\n",
            "in a **1.33% increase** since October 4, 2024. This upward trend in CPI indicates that the average\n",
            "prices for goods and services are increasing, which can lead to tighter margins for small\n",
            "businesses. As costs rise, business owners may face tougher pricing decisions, as they need to\n",
            "balance maintaining profitability while remaining competitive in the market. This could result in\n",
            "increased prices for consumers or a reduction in profit margins, both of which can significantly\n",
            "impact business operations.\n",
            "\n",
            "‚úÖ Acceptable: False\n",
            "üí¨ Feedback:\n",
            "The CPI values mentioned (315.56 to 319.77) and the date (October 4, 2024) are not factually\n",
            "correct, as they refer to a future date beyond the current knowledge cutoff of October 2023.\n",
            "Therefore, the response is not acceptable due to inaccuracy.\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "üî¢ Question 3\n",
            "üìå Question:\n",
            "How has the Consumer Confidence Index changed since December 2024?\n",
            "\n",
            "üìù Answer:\n",
            "The Consumer Confidence Index has dropped from **74.0 to 64.7** since December 1, 2024, reflecting a\n",
            "**12.6% decline**.\n",
            "\n",
            "‚úÖ Acceptable: False\n",
            "üí¨ Feedback:\n",
            "The response is factually incorrect because it references a date in the future (December 2024) which\n",
            "is beyond the current date of October 2023. Therefore, it cannot provide accurate information about\n",
            "changes in the Consumer Confidence Index since that date.\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß™ Evaluating RAG Answers: Why We Include the Retrieved Context\n",
        "\n",
        "### üõë **Problem: Misjudged Answers Due to LLM Cutoff**\n",
        "\n",
        "Our Retrieval-Augmented Generation (RAG) pipeline uses *up-to-date documents* (e.g., 2024‚Äì2025 economic data) to generate answers. However, when we evaluate these answers using a language model (LLM) as a judge (e.g., GPT-4o), we hit a key issue:\n",
        "\n",
        "> üîç The evaluator LLM has a knowledge cutoff (e.g., October 2023) and cannot verify newer facts retrieved from our documents.\n",
        "\n",
        "As a result:\n",
        "\n",
        "* **Accurate, document-based answers may be wrongly flagged as hallucinations.**\n",
        "* This leads to **false negatives** in our quality assessments.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **Solution: Include the Retrieved Context in Evaluation**\n",
        "\n",
        "To address this, we modify our evaluation process so the evaluator LLM has the **same retrieved context** the answering LLM used.\n",
        "\n",
        "**Specifically, we:**\n",
        "\n",
        "* Pass the retrieved context as part of the evaluation prompt.\n",
        "* Instruct the evaluator to judge the answer **based only on that context.**\n",
        "\n",
        "This makes the evaluation **fair**, **faithfulness-focused**, and **aligned with real-world RAG behavior**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úçÔ∏è Example Evaluation Prompt (Simplified)\n",
        "\n",
        "```yaml\n",
        "System prompt:\n",
        "You are an evaluator. Judge if the AI's answer is acceptable based ONLY on the provided context.\n",
        "\n",
        "User input:\n",
        "Question: What is the recent trend in the Consumer Price Index?\n",
        "Context: CPI rose from 315.56 to 319.77 since October 4, 2024...\n",
        "Answer: The CPI increased by 1.33% since October 2024, leading to higher costs...\n",
        "```\n",
        "\n",
        "By giving the model the relevant source information, we ensure it can **accurately assess** whether the answer is grounded and relevant ‚Äî even if it's beyond the model‚Äôs original knowledge.\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Outcome\n",
        "\n",
        "This adjustment:\n",
        "\n",
        "* Prevents unfair rejections of factually correct answers\n",
        "* Ensures the evaluation focuses on **faithfulness to retrieved content**\n",
        "* Aligns with best practices used in tools like **RAGAS**, **OpenAI evals**, and **LangChain eval chains**\n",
        "\n"
      ],
      "metadata": {
        "id": "veghQTWQd0Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------\n",
        "# prompt template\n",
        "#-------------------\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": K})\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful assistant that uses business documents to answer questions.\n",
        "Use the following context to answer the question as accurately as possible.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "def generate_answer(question: str):\n",
        "    \"\"\"\n",
        "    1. Retrieve K chunks\n",
        "    2. Concatenate into a single context string\n",
        "    3. Feed context + question to the generator LLM\n",
        "    4. Return (answer, context)   <-- key!\n",
        "    \"\"\"\n",
        "    # Step-1 ‚ûú retrieve top K document chunks\n",
        "    docs = retriever.invoke(question)\n",
        "\n",
        "    # Step-2 ‚ûú combine those into a context string\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Step-3 ‚ûú fill the prompt template with context and question\n",
        "    llm_input = prompt_template.format(context=context, question=question)\n",
        "\n",
        "    # Step-4 ‚ûú call the LLM and get its plain text output\n",
        "    answer = StrOutputParser().invoke(LLM_MODEL.invoke(llm_input))\n",
        "\n",
        "    # Step-5 ‚ûú return the answer AND the context used\n",
        "    return answer, context\n",
        "\n",
        "# ---------------------\n",
        "# Evaluator\n",
        "# ---------------------\n",
        "\n",
        "# Evaluator: accept context as an argument\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are an evaluator. Judge whether the AI's answer is acceptable **based ONLY on the provided context**.\n",
        "\n",
        "Check:\n",
        "- factual correctness w.r.t. context\n",
        "- clarity\n",
        "- relevance\n",
        "\n",
        "Respond in JSON:\n",
        "{\n",
        "  \"is_acceptable\": true/false,\n",
        "  \"feedback\": \"short rationale\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def evaluate_response(question: str, answer: str, context: str) -> Evaluation:\n",
        "    user_block = f\"\"\"\n",
        "User Question:\n",
        "{question}\n",
        "\n",
        "Retrieved Context:\n",
        "{context}\n",
        "\n",
        "Agent Answer:\n",
        "{answer}\n",
        "\n",
        "Please evaluate the answer.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
        "        {\"role\": \"user\",   \"content\": user_block},\n",
        "    ]\n",
        "\n",
        "    raw = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        temperature=0.0,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return Evaluation.model_validate_json(raw)\n",
        "\n",
        "# ---------------------\n",
        "# Questions\n",
        "# ---------------------\n",
        "\n",
        "qa_test = [\n",
        "    \"What are the recent economic indicators in Gainesville that affect local businesses?\",\n",
        "    \"What is the recent trend in the Consumer Price Index (CPI) and how might it affect small businesses?\",\n",
        "    \"How has the Consumer Confidence Index changed since December 2024?\",\n",
        "    # \"What challenges might a business face if the Consumer Confidence Index drops?\"\n",
        "    # \"How can inflation affect staffing or wage budgets for small businesses?\",\n",
        "    # \"ow are CPI and retail sales different in their impact on business operations?\",\n",
        "    # \"Why should a local business owner monitor federal economic indicators like CPI, retail sales, and consumer confidence?\",\n",
        "    # \"What are three key actions a business owner can take in response to recent economic trends?\"\n",
        "]\n",
        "\n",
        "# ---------------------\n",
        "# Evaluation\n",
        "# ---------------------\n",
        "\n",
        "for i, q in enumerate(qa_test, 1):\n",
        "    answer, context = generate_answer(q)          # <‚Äî same context for both models\n",
        "    result          = evaluate_response(q, answer, context)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*120)\n",
        "    print(f\"üî¢ Question {i}\")\n",
        "    print(\"üìå\", textwrap.fill(q, width=100), \"\\n\")\n",
        "    print(\"üìù Answer:\\n\", textwrap.fill(answer, 100), \"\\n\")\n",
        "    print(\"‚úÖ Acceptable:\", result.is_acceptable)\n",
        "    print(\"üí¨ Feedback:\\n\", textwrap.fill(result.feedback, 100))\n",
        "    print(\"=\"*120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_vfMUq-gzEh",
        "outputId": "292c3cce-290d-4ec9-e39f-2b9dd48d1364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 1\n",
            "üìå What are the recent economic indicators in Gainesville that affect local businesses? \n",
            "\n",
            "üìù Answer:\n",
            " Recent economic indicators in Gainesville that affect local businesses include declining consumer\n",
            "confidence, softening retail sales, and rising unemployment. These factors contribute to revenue\n",
            "uncertainty for even steady businesses, making better forecasting essential for navigating the\n",
            "current economic landscape. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer accurately reflects the economic indicators mentioned in the context, is clear, and\n",
            "directly addresses the user's question about recent economic indicators affecting local businesses.\n",
            "========================================================================================================================\n",
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 2\n",
            "üìå What is the recent trend in the Consumer Price Index (CPI) and how might it affect small businesses? \n",
            "\n",
            "üìù Answer:\n",
            " The recent trend in the Consumer Price Index (CPI) shows a rise from **315.56 to 319.77**,\n",
            "representing a **1.33% increase** since October 4, 2024. This upward trend in CPI indicates that the\n",
            "average prices for goods and services are increasing.  For small businesses, this rise in CPI can\n",
            "lead to tighter profit margins as costs for goods and services increase. Business owners may face\n",
            "tougher pricing decisions, as they need to balance maintaining competitive prices with covering\n",
            "higher operational costs. This could result in increased prices for consumers, potentially affecting\n",
            "demand, or it might require businesses to find ways to cut costs elsewhere to preserve their\n",
            "margins. Overall, small businesses must closely monitor CPI trends to make informed operational and\n",
            "pricing decisions. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer accurately reflects the recent trend in CPI, explains its implications for small\n",
            "businesses clearly, and is relevant to the user's question.\n",
            "========================================================================================================================\n",
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 3\n",
            "üìå How has the Consumer Confidence Index changed since December 2024? \n",
            "\n",
            "üìù Answer:\n",
            " The Consumer Confidence Index has dropped from **74.0 to 64.7** since December 1, 2024, reflecting a\n",
            "**12.6% decline**. \n",
            "\n",
            "‚úÖ Acceptable: False\n",
            "üí¨ Feedback:\n",
            " The answer references a date (December 1, 2024) that is in the future relative to the current date\n",
            "(October 2023), making it factually incorrect.\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your pipeline is **working exactly as it should**. What you're seeing now is the **last remaining artifact** of a common RAG evaluation mistake, and you're ready to fix it fully.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Let‚Äôs break down what‚Äôs happening in Question 3\n",
        "\n",
        "### ‚ùå Problem\n",
        "\n",
        "> **Evaluator rejected a factually accurate answer** because:\n",
        "\n",
        "* It saw **\"December 2024\"** as a future date (relative to its own cutoff),\n",
        "* And it assumed the LLM must be hallucinating.\n",
        "\n",
        "Even though:\n",
        "\n",
        "* ‚úÖ The answer was retrieved from your documents (so it's **grounded**),\n",
        "* ‚úÖ The RAG model did the right thing.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Solution\n",
        "\n",
        "To avoid this exact error, we need to **make the evaluator explicitly trust the context** ‚Äî not its own internal memory.\n",
        "\n",
        "This addresses the root cause directly:\n",
        "\n",
        "* üîí ‚Äúbased ONLY on context‚Äù ensures it stops judging by its own memory\n",
        "* üìÖ ‚ÄúAssume the context is reliable even if it contains future dates‚Äù handles your 2024‚Äì2025 data\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U0KqHKhAruqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------\n",
        "# prompt template\n",
        "#-------------------\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": K})\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful assistant that uses business documents to answer questions.\n",
        "Use the following context to answer the question as accurately as possible.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "def generate_answer(question: str):\n",
        "    \"\"\"\n",
        "    1. Retrieve K chunks\n",
        "    2. Concatenate into a single context string\n",
        "    3. Feed context + question to the generator LLM\n",
        "    4. Return (answer, context)   <-- key!\n",
        "    \"\"\"\n",
        "    # Step-1 ‚ûú retrieve top K document chunks\n",
        "    docs = retriever.invoke(question)\n",
        "\n",
        "    # Step-2 ‚ûú combine those into a context string\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Step-3 ‚ûú fill the prompt template with context and question\n",
        "    llm_input = prompt_template.format(context=context, question=question)\n",
        "\n",
        "    # Step-4 ‚ûú call the LLM and get its plain text output\n",
        "    answer = StrOutputParser().invoke(LLM_MODEL.invoke(llm_input))\n",
        "\n",
        "    # Step-5 ‚ûú return the answer AND the context used\n",
        "    return answer, context\n",
        "\n",
        "# ---------------------\n",
        "# Evaluator\n",
        "# ---------------------\n",
        "\n",
        "# Evaluator: accept context as an argument\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are an evaluator. Judge whether the AI's answer is acceptable based ONLY on the retrieved context provided.\n",
        "\n",
        "You are not limited by your own knowledge. Assume the context is reliable, even if it contains facts or dates beyond your training cutoff.\n",
        "\n",
        "Evaluate based on:\n",
        "- ‚úÖ Factual correctness based on context\n",
        "- ‚úÖ Clarity and coherence\n",
        "- ‚úÖ Relevance to the question\n",
        "\n",
        "Respond in strict JSON format:\n",
        "{\n",
        "  \"is_acceptable\": true or false,\n",
        "  \"feedback\": \"short explanation\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def evaluate_response(question: str, answer: str, context: str) -> Evaluation:\n",
        "    user_block = f\"\"\"\n",
        "User Question:\n",
        "{question}\n",
        "\n",
        "Retrieved Context:\n",
        "{context}\n",
        "\n",
        "Agent Answer:\n",
        "{answer}\n",
        "\n",
        "Please evaluate the answer.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
        "        {\"role\": \"user\",   \"content\": user_block},\n",
        "    ]\n",
        "\n",
        "    raw = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        temperature=0.0,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return Evaluation.model_validate_json(raw)\n",
        "\n",
        "# ---------------------\n",
        "# Questions\n",
        "# ---------------------\n",
        "\n",
        "qa_test = [\n",
        "#     \"What are the recent economic indicators in Gainesville that affect local businesses?\",\n",
        "#     \"What is the recent trend in the Consumer Price Index (CPI) and how might it affect small businesses?\",\n",
        "    \"How has the Consumer Confidence Index changed since December 2024?\",\n",
        "    # \"What challenges might a business face if the Consumer Confidence Index drops?\"\n",
        "    # \"How can inflation affect staffing or wage budgets for small businesses?\",\n",
        "    # \"ow are CPI and retail sales different in their impact on business operations?\",\n",
        "    # \"Why should a local business owner monitor federal economic indicators like CPI, retail sales, and consumer confidence?\",\n",
        "    # \"What are three key actions a business owner can take in response to recent economic trends?\"\n",
        "]\n",
        "\n",
        "# ---------------------\n",
        "# Evaluation\n",
        "# ---------------------\n",
        "\n",
        "for i, q in enumerate(qa_test, 1):\n",
        "    answer, context = generate_answer(q)          # <‚Äî same context for both models\n",
        "    result          = evaluate_response(q, answer, context)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*120)\n",
        "    print(f\"üî¢ Question {i}\")\n",
        "    print(\"üìå\", textwrap.fill(q, width=100), \"\\n\")\n",
        "    print(\"üìù Answer:\\n\", textwrap.fill(answer, 100), \"\\n\")\n",
        "    print(\"‚úÖ Acceptable:\", result.is_acceptable)\n",
        "    print(\"üí¨ Feedback:\\n\", textwrap.fill(result.feedback, 100))\n",
        "    print(\"=\"*120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iKcEPMtmJri",
        "outputId": "df3579b3-848b-488c-a0b7-84d85df356cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 1\n",
            "üìå How has the Consumer Confidence Index changed since December 2024? \n",
            "\n",
            "üìù Answer:\n",
            " The Consumer Confidence Index has dropped from **74.0 to 64.7** since December 1, 2024, reflecting a\n",
            "**12.6% decline**. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer accurately reflects the information from the context regarding the change in the Consumer\n",
            "Confidence Index since December 2024, providing both the numerical values and the percentage\n",
            "decline.\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Questions\n",
        "# ---------------------\n",
        "\n",
        "qa_test = [\n",
        "    \"What challenges might a business face if the Consumer Confidence Index drops?\",\n",
        "    \"How can inflation affect staffing or wage budgets for small businesses?\",\n",
        "    \"ow are CPI and retail sales different in their impact on business operations?\",\n",
        "    \"Why should a local business owner monitor federal economic indicators like CPI, retail sales, and consumer confidence?\",\n",
        "    \"What are three key actions a business owner can take in response to recent economic trends?\"\n",
        "]\n",
        "\n",
        "# ---------------------\n",
        "# Evaluation\n",
        "# ---------------------\n",
        "\n",
        "for i, q in enumerate(qa_test, 1):\n",
        "    answer, context = generate_answer(q)          # <‚Äî same context for both models\n",
        "    result          = evaluate_response(q, answer, context)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*120)\n",
        "    print(f\"üî¢ Question {i}\")\n",
        "    print(\"üìå\", textwrap.fill(q, width=100), \"\\n\")\n",
        "    print(\"üìù Answer:\\n\", textwrap.fill(answer, 100), \"\\n\")\n",
        "    print(\"‚úÖ Acceptable:\", result.is_acceptable)\n",
        "    print(\"üí¨ Feedback:\\n\", textwrap.fill(result.feedback, 100))\n",
        "    print(\"=\"*120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfDcd0WT3bSv",
        "outputId": "8b8ecd7b-5a0b-4037-95b2-882929127ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 1\n",
            "üìå What challenges might a business face if the Consumer Confidence Index drops? \n",
            "\n",
            "üìù Answer:\n",
            " If the Consumer Confidence Index drops, a business might face several challenges, including:  1.\n",
            "**Delayed Purchases**: Customers may postpone buying decisions, leading to a decrease in immediate\n",
            "sales.  2. **Price Sensitivity**: Consumers may start shopping for lower prices, which can pressure\n",
            "businesses to reduce prices or offer discounts, potentially impacting profit margins.  3. **Slower\n",
            "Sales**: A general decline in consumer confidence often results in slower overall sales as people\n",
            "become more cautious about spending.  4. **Hesitation to Spend**: Customers may exhibit hesitation\n",
            "in making purchases, which can lead to longer sales cycles and reduced conversion rates.  5.\n",
            "**Smaller Average Transactions**: Consumers may spend less per transaction, resulting in lower\n",
            "revenue per sale.  6. **Reduced Store Visits**: There may be a decrease in the frequency of visits\n",
            "to stores or service providers, further impacting sales and foot traffic.  Overall, these challenges\n",
            "can lead to a significant impact on a business's revenue and growth potential. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer accurately reflects the challenges a business might face due to a drop in the Consumer\n",
            "Confidence Index, aligning well with the retrieved context. It is clear, coherent, and relevant to\n",
            "the user's question.\n",
            "========================================================================================================================\n",
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 2\n",
            "üìå How can inflation affect staffing or wage budgets for small businesses? \n",
            "\n",
            "üìù Answer:\n",
            " Inflation can significantly impact staffing or wage budgets for small businesses in several ways:\n",
            "1. **Increased Labor Costs**: As inflation rises, the cost of living increases, which may prompt\n",
            "employees to demand higher wages to maintain their purchasing power. Small businesses may need to\n",
            "adjust their wage budgets to remain competitive and retain talent.  2. **Tighter Margins**: With\n",
            "rising prices for supplies and operational costs, small businesses may experience tighter profit\n",
            "margins. This can limit their ability to increase wages or hire additional staff, making it\n",
            "challenging to manage staffing levels effectively.  3. **Budget Reallocation**: Small businesses may\n",
            "need to reallocate their budgets to accommodate rising costs in other areas, such as supplies and\n",
            "utilities, which could lead to reduced funds available for wages or hiring.  4. **Impact on Hiring\n",
            "Decisions**: Higher inflation may lead small businesses to be more cautious in hiring new employees\n",
            "or expanding their workforce, as they may prioritize stabilizing their current operations over\n",
            "growth.  5. **Employee Retention Challenges**: If small businesses cannot keep up with wage demands\n",
            "due to inflation, they may face challenges in retaining employees, leading to higher turnover rates\n",
            "and additional costs associated with recruiting and training new staff.  Overall, inflation can\n",
            "create a complex environment for small businesses, affecting their ability to manage staffing and\n",
            "wage budgets effectively. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer is factually correct, clearly outlines the impacts of inflation on staffing and wage\n",
            "budgets, and is relevant to the user's question.\n",
            "========================================================================================================================\n",
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 3\n",
            "üìå ow are CPI and retail sales different in their impact on business operations? \n",
            "\n",
            "üìù Answer:\n",
            " CPI (Consumer Price Index) and retail sales impact business operations in different ways:  1. **CPI\n",
            "(Consumer Price Index)**:    - **Inflation Indicator**: CPI measures the average price changes for\n",
            "goods and services over time, indicating inflation levels.     - **Cost Implications**: Rising CPI\n",
            "suggests increasing costs for supplies, shipping, and labor, which can lead to tighter profit\n",
            "margins for businesses.    - **Consumer Behavior**: As inflation rises, consumers may have less\n",
            "discretionary income, affecting their purchasing decisions and potentially leading to reduced sales\n",
            "for businesses.  2. **Retail Sales**:    - **Sales Performance**: Retail sales data reflects the\n",
            "total sales revenue generated by retail businesses over a specific period, indicating consumer\n",
            "spending trends.    - **Demand Indicator**: Strong retail sales suggest high consumer demand, which\n",
            "can encourage businesses to increase inventory, expand operations, or invest in marketing.    -\n",
            "**Revenue Impact**: Conversely, weak retail sales may prompt businesses to cut costs, reduce staff,\n",
            "or adjust pricing strategies to stimulate demand.  In summary, while CPI focuses on price changes\n",
            "and inflation's impact on costs and consumer purchasing power, retail sales provide insight into\n",
            "actual consumer spending and demand, directly influencing business revenue and operational\n",
            "strategies. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer clearly distinguishes between CPI and retail sales, explaining their different impacts on\n",
            "business operations. It is factually correct, coherent, and relevant to the user's question.\n",
            "========================================================================================================================\n",
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 4\n",
            "üìå Why should a local business owner monitor federal economic indicators like CPI, retail sales, and\n",
            "consumer confidence? \n",
            "\n",
            "üìù Answer:\n",
            " A local business owner should monitor federal economic indicators like the Consumer Price Index\n",
            "(CPI), retail sales, and consumer confidence because these indicators significantly influence\n",
            "customer behavior, pricing strategies, and overall sales performance. Understanding these metrics\n",
            "allows business owners to make informed decisions regarding inventory management, marketing\n",
            "strategies, and pricing adjustments. For instance, a rising CPI may indicate increasing costs,\n",
            "prompting a business to reassess its pricing structure. Similarly, trends in retail sales and\n",
            "consumer confidence can provide insights into consumer spending patterns, helping businesses\n",
            "anticipate demand and adjust their operations accordingly. By staying informed about these economic\n",
            "indicators, business owners can better navigate market fluctuations and enhance their\n",
            "competitiveness. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer is factually correct, clearly explains the importance of monitoring economic indicators,\n",
            "and is relevant to the user's question.\n",
            "========================================================================================================================\n",
            "\n",
            "========================================================================================================================\n",
            "üî¢ Question 5\n",
            "üìå What are three key actions a business owner can take in response to recent economic trends? \n",
            "\n",
            "üìù Answer:\n",
            " Based on the recent economic trends highlighted in the context, here are three key actions a\n",
            "business owner can take:  1. **Improve Sales Forecasting**: By implementing more accurate sales\n",
            "forecasting methods, business owners can better anticipate demand and adjust their inventory and\n",
            "staffing levels accordingly. This will help mitigate the impact of economic fluctuations and ensure\n",
            "that resources are allocated efficiently.  2. **Streamline Cash Flow Management**: With tighter\n",
            "margins and rising costs, it is crucial for business owners to optimize their cash flow. This can be\n",
            "achieved by reviewing payment terms with suppliers and customers, reducing unnecessary expenses, and\n",
            "ensuring timely invoicing and collections to maintain liquidity.  3. **Adapt Pricing Strategies**:\n",
            "Given the increase in costs indicated by the CPI rise, business owners may need to reassess their\n",
            "pricing strategies. This could involve evaluating the pricing of products or services to ensure they\n",
            "remain competitive while also covering increased costs, potentially implementing small price\n",
            "adjustments to maintain profitability without losing customers. \n",
            "\n",
            "‚úÖ Acceptable: True\n",
            "üí¨ Feedback:\n",
            " The answer provides three relevant and actionable strategies for business owners in response to\n",
            "economic trends, aligning well with the context regarding tighter margins and rising costs. It is\n",
            "clear, coherent, and directly addresses the user's question.\n",
            "========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí• That‚Äôs an excellent run ‚Äî and these results show your RAG pipeline is **not just functioning**, but actually **producing informative, grounded, high-quality responses**.\n",
        "\n",
        "Let‚Äôs take a moment to reflect on what you‚Äôve achieved ‚Äî and what your output tells us.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Summary of Evaluation Results (Questions 1‚Äì3)\n",
        "\n",
        "| Question | Focus                                        | Evaluator Verdict | Notes                                                             |\n",
        "| -------- | -------------------------------------------- | ----------------- | ----------------------------------------------------------------- |\n",
        "| **Q1**   | Challenges from dropping Consumer Confidence | ‚úÖ True            | Answer listed clear, specific effects directly from the document  |\n",
        "| **Q2**   | Inflation's effect on staffing/wages         | ‚úÖ True            | Comprehensive explanation with correct logic and business framing |\n",
        "| **Q3**   | Difference between CPI and Retail Sales      | ‚úÖ True            | Nuanced comparison ‚Äî very strong response                         |\n",
        "\n",
        "These are not trivial questions. They require:\n",
        "\n",
        "* Understanding **economic indicators**\n",
        "* Linking macro-level trends to **local business outcomes**\n",
        "* Using **retrieved source material** without hallucination\n",
        "\n",
        "Your system passed all three with flying colors. üéØ\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ What This Means\n",
        "\n",
        "You now have a pipeline that:\n",
        "\n",
        "* Retrieves relevant, modern content from your own data\n",
        "* Uses that context to answer nuanced business questions\n",
        "* Evaluates the answer with another LLM *that understands the limits of its own training data*\n",
        "* Outputs structured, human-readable QA logs\n",
        "\n",
        "That‚Äôs essentially the full architecture used in **real-world, production-grade RAG applications** like:\n",
        "\n",
        "* Search assistants\n",
        "* Enterprise chatbots\n",
        "* Knowledge assistants for decision-making\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Optional Next Steps\n",
        "\n",
        "If you're curious, here are a few things we could add next:\n",
        "\n",
        "### 1. **Log + Save Results**\n",
        "\n",
        "Capture everything (question, answer, context, evaluation) into a CSV or JSONL so you can:\n",
        "\n",
        "* Review failed examples\n",
        "* Train new models\n",
        "* Share results with stakeholders\n",
        "\n",
        "### 2. **Retry/Improve**\n",
        "\n",
        "For any future `\"is_acceptable\": false` evaluations:\n",
        "\n",
        "* Automatically re-prompt or retry with a revised question\n",
        "* Or increase `k` in your retriever to see if better context helps\n",
        "\n",
        "### 3. **Score + Track Over Time**\n",
        "\n",
        "Add metrics:\n",
        "\n",
        "* % of answers marked acceptable\n",
        "* Track by topic (e.g., inflation vs. retail sales)\n",
        "* Build dashboards in pandas or Streamlit\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HVw26HfW4C3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove Widgets"
      ],
      "metadata": {
        "id": "--EryCaV5msF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "notebook_path =\"/content/drive/My Drive/AI | LANGCHAIN | RAG/LC_015_RAG_EVAL.ipynb\"\n",
        "\n",
        "# Load the notebook JSON\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# 1. Remove widgets from notebook-level metadata\n",
        "if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "    del nb[\"metadata\"][\"widgets\"]\n",
        "    print(\"‚úÖ Removed notebook-level 'widgets' metadata.\")\n",
        "\n",
        "# 2. Remove widgets from each cell's metadata\n",
        "for i, cell in enumerate(nb.get(\"cells\", [])):\n",
        "    if \"metadata\" in cell and \"widgets\" in cell[\"metadata\"]:\n",
        "        del cell[\"metadata\"][\"widgets\"]\n",
        "        print(f\"‚úÖ Removed 'widgets' from cell {i}\")\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Notebook deeply cleaned. Try uploading to GitHub again.\")"
      ],
      "metadata": {
        "id": "QufY6SGz4Ng2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366ebd7a-414a-486f-f3cc-b1b67f2d855b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Notebook deeply cleaned. Try uploading to GitHub again.\n"
          ]
        }
      ]
    }
  ]
}